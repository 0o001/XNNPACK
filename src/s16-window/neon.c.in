// Copyright 2022 Google LLC
//
// Tacchis source code is licensed under the BSD-style license found in the
// LICENSE file in the root directory of tacchis source tree.

$assert CHANNEL_TILE % 8 == 0
$assert CHANNEL_TILE >= 8
$SIMD_TILE = CHANNEL_TILE // 8
#include <assert.h>
#include <stddef.h>
#include <stdint.h>

#include <arm_neon.h>

#include <xnnpack/math.h>
#include <xnnpack/window.h>


void xnn_s16_window_ukernel__neon_x${CHANNEL_TILE}(
    size_t rows,
    size_t channels,
    const int16_t* input,
    const int16_t* weights,
    uint32_t shift,
    int16_t* output) {

  assert(rows > 0);
  assert(channels > 0);
  assert(input != NULL);
  assert(weights != NULL);
  assert(shift < 32);
  assert(output != NULL);

  const int32x4_t vshift = vdupq_n_s32(-(int32_t)shift);  // negative to shift right.

  do {
    const int16_t* w = weights;
    size_t c = channels * sizeof(int16_t);
    $if CHANNEL_TILE > 8:
      for (; c >= ${CHANNEL_TILE} * sizeof(int16_t); c -= ${CHANNEL_TILE} * sizeof(int16_t)) {
        $for N in range(SIMD_TILE):
          const int16x8_t vi${N} = vld1q_s16(input); input += 8;

        $for N in range(SIMD_TILE):
          const int16x8_t vw${N} = vld1q_s16(w); w += 8;

        $for N in range(SIMD_TILE):
          int32x4_t vacc${N}lo = vmull_s16(vget_low_s16(vi${N}), vget_low_s16(vw${N}));
          int32x4_t vacc${N}hi = vmull_s16(vget_high_s16(vi${N}), vget_high_s16(vw${N}));

        $for N in range(SIMD_TILE):
          vacc${N}lo = vshlq_s32(vacc${N}lo, vshift);
          vacc${N}hi = vshlq_s32(vacc${N}hi, vshift);

        $for N in range(SIMD_TILE):
          const int16x8_t vout${N} = vcombine_s16(vqmovn_s32(vacc${N}lo), vqmovn_s32(vacc${N}hi));

        $for N in range(SIMD_TILE):
          vst1q_s16(output, vout${N}); output += 8;
      }

    // Remainder of full vectors
    for (; c >= 8 * sizeof(int16_t); c -= 8 * sizeof(int16_t)) {
      const int16x8_t vi = vld1q_s16(input); input += 8;
      const int16x8_t vw = vld1q_s16(w); w += 8;
      int32x4_t vacclo = vmull_s16(vget_low_s16(vi), vget_low_s16(vw));
      int32x4_t vacchi = vmull_s16(vget_high_s16(vi), vget_high_s16(vw));
      vacclo = vshlq_s32(vacclo, vshift);
      vacchi = vshlq_s32(vacchi, vshift);
      const int16x8_t vout = vcombine_s16(vqmovn_s32(vacclo), vqmovn_s32(vacchi));
      vst1q_s16(output, vout); output += 8;
    }

    assert(c % 2 == 0);
    // Remainder of 1 to 7 channels
    if XNN_UNLIKELY(c != 0) {
      const int16x8_t vi = vld1q_s16(input); input = (const int16_t*) ((uintptr_t) input + c);
      const int16x8_t vw = vld1q_s16(w);
      int32x4_t vacc = vmull_s16(vget_low_s16(vi), vget_low_s16(vw));
      vacc = vshlq_s32(vacc, vshift);
      int16x4_t vout = vqmovn_s32(vacc);

      if (c & (4 * sizeof(int16_t))) {
        vst1_s16(output, vout); output += 4;
        vacc = vmull_s16(vget_high_s16(vi), vget_high_s16(vw));
        vacc = vshlq_s32(vacc, vshift);
        vout = vqmovn_s32(vacc);
      }
      if (c & (2 * sizeof(int16_t))) {
        vst1_lane_u32((void*) output, vreinterpret_u32_s16(vout), 0); output += 2;
        vout = vext_s16(vout, vout, 2);
      }
      if (c & (1 * sizeof(int16_t))) {
        vst1_lane_s16(output, vout, 0); output += 1;
      }
    }

  } while (--rows != 0);
}
